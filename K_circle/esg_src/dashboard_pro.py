import os
import time
import json
import math
import requests
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import yfinance as yf
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from datetime import datetime, timedelta

# -----------------------------------------------------
# ê¸°ë³¸ ì„¤ì •
# -----------------------------------------------------
st.set_page_config(page_title="ESG ê¸°ë°˜ AI íˆ¬ìì§€ì›", layout="wide")
st.title("ğŸ“Š ESG ê¸°ë°˜ AI íˆ¬ìì§€ì› ëŒ€ì‹œë³´ë“œ")
st.caption("B.B.BIC | ì‹¤ì‹œê°„(ë˜ëŠ” ì¤€ì‹¤ì‹œê°„) ìˆ˜ì§‘ â†’ AI ì ìˆ˜í™” â†’ ëŒ€ì‹œë³´ë“œ")

# ê¸°ì—… ëª©ë¡ê³¼ í‹°ì»¤ ë§¤í•‘ (ì›í•˜ëŠ” ê¸°ì—… ììœ  ì¶”ê°€)
COMPANY_MAP = {
    "ì‚¼ì„±ì „ì": {"ticker": "005930.KS", "query": "ì‚¼ì„±ì „ì ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
    "SKí•˜ì´ë‹‰ìŠ¤": {"ticker": "000660.KS", "query": "SKí•˜ì´ë‹‰ìŠ¤ ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
    "LGì „ì": {"ticker": "066570.KS", "query": "LGì „ì ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
    "í˜„ëŒ€ìë™ì°¨": {"ticker": "005380.KS", "query": "í˜„ëŒ€ìë™ì°¨ ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
    "NAVER": {"ticker": "035420.KS", "query": "ë„¤ì´ë²„ ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
    "í•œí™”ì†”ë£¨ì…˜": {"ticker": "009830.KS", "query": "í•œí™”ì†”ë£¨ì…˜ ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
    
    # ì—¬ê¸°ì— ê¸°ì—… ì¶”ê°€!
    "ì¹´ì¹´ì˜¤": {"ticker": "035720.KS", "query": "ì¹´ì¹´ì˜¤ ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
    "ì‚¼ì„±SDI": {"ticker": "006400.KS", "query": "ì‚¼ì„±SDI ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
    "LGí™”í•™": {"ticker": "051910.KS", "query": "LGí™”í•™ ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
    "í¬ìŠ¤ì½”í™€ë”©ìŠ¤": {"ticker": "005490.KS", "query": "í¬ìŠ¤ì½” ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
    "ê¸°ì•„": {"ticker": "000270.KS", "query": "ê¸°ì•„ ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
    "KBê¸ˆìœµ": {"ticker": "105560.KS", "query": "KBê¸ˆìœµ ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
    "ì‹ í•œì§€ì£¼": {"ticker": "055550.KS", "query": "ì‹ í•œì§€ì£¼ ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
    "ì…€íŠ¸ë¦¬ì˜¨": {"ticker": "068270.KS", "query": "ì…€íŠ¸ë¦¬ì˜¨ ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
    "í˜„ëŒ€ëª¨ë¹„ìŠ¤": {"ticker": "012330.KS", "query": "í˜„ëŒ€ëª¨ë¹„ìŠ¤ ESG OR ì¹œí™˜ê²½ OR íƒ„ì†Œì¤‘ë¦½"},
}
# -----------------------------------------------------
# ì‚¬ì´ë“œë°” í•„í„°
# -----------------------------------------------------
st.sidebar.header("âš™ï¸ í•„í„°")
days = st.sidebar.slider("ë‰´ìŠ¤ ë¶„ì„ ê¸°ê°„(ì¼)", 7, 60, 14, 1)
companies = st.sidebar.multiselect(
    "ëŒ€ìƒ ê¸°ì—…", list(COMPANY_MAP.keys()), default=list(COMPANY_MAP.keys())[:4]
)
if not companies:
    st.warning("ìµœì†Œ 1ê°œ ê¸°ì—…ì„ ì„ íƒí•˜ì„¸ìš”.")
    st.stop()

# -----------------------------------------------------
# ìœ í‹¸: ìºì‹œ ì˜µì…˜
# -----------------------------------------------------
@st.cache_data(ttl=60*30)  # 30ë¶„ ìºì‹œ
def cached_json_get(url, headers=None, params=None):
    r = requests.get(url, headers=headers, params=params, timeout=15)
    r.raise_for_status()
    return r.json()

@st.cache_data(ttl=60*60)  # 1ì‹œê°„ ìºì‹œ
def fetch_yf_history(ticker: str, start_date: str):
    try:
        data = yf.download(ticker, start=start_date)
        if data is None or data.empty:
            return pd.DataFrame()
        hist = data.reset_index()[["Date", "Close"]]
        hist.rename(columns={"Date":"date","Close":"stock_price"}, inplace=True)
        hist["year"] = hist["date"].dt.year
        return hist
    except Exception:
        return pd.DataFrame()

@st.cache_data(ttl=60*60)
def fetch_yf_fastinfo(ticker: str):
    try:
        t = yf.Ticker(ticker)
        fi = getattr(t, "fast_info", None) or {}
        # yfinance fast_infoê°€ ì—†ëŠ” ì¢…ëª©ë„ ìˆì–´ ë°©ì–´ì  ì²˜ë¦¬
        market_cap = fi.get("market_cap")
        return market_cap
    except Exception:
        return None

# -----------------------------------------------------
# ë‰´ìŠ¤ ìˆ˜ì§‘ (NewsAPI â†’ ì—†ìœ¼ë©´ Naver â†’ ì—†ìœ¼ë©´ ìƒ˜í”Œ)
# -----------------------------------------------------
def fetch_news(company: str, query: str, days_back: int):
    until = datetime.utcnow()
    since = until - timedelta(days=days_back)
    news = []

    # API í‚¤ ì§ì ‘ ì…ë ¥
    news_api_key = st.secrets.get("NEWS_API_KEY")  # tomlì—ì„œ ì½ê¸°
    
    if news_api_key:
        url = "https://newsapi.org/v2/everything"
        params = {
            "q": query,
            "from": since.strftime("%Y-%m-%d"),
            "to": until.strftime("%Y-%m-%d"),
            "sortBy": "relevancy",
            "language": "ko",
            "pageSize": 50,
            "apiKey": news_api_key,
        }
        try:
            data = cached_json_get(url, params=params)
            for a in data.get("articles", []):
                title = a.get("title", "")
                desc = a.get("description", "")
                content = (title or "") + " " + (desc or "")
                news.append({"company":company, "date":a.get("publishedAt","")[:10], "source":"newsapi", "content":content})
        except Exception:
            pass

    # ìƒ˜í”Œ ë°ì´í„° (ë°±ì—…)
    if not news:
        samples = [
            f"{company} íƒ„ì†Œì¤‘ë¦½ ë¡œë“œë§µ ë°œí‘œ, ì¬ìƒì—ë„ˆì§€ ì‚¬ìš© í™•ëŒ€",
            f"{company} í˜‘ë ¥ì‚¬ì™€ì˜ ìƒìƒ í”„ë¡œê·¸ë¨ ê°•í™”, ì‚¬íšŒì  ì±…ì„ í™•ëŒ€",
            f"{company} ESG ìœ„ì›íšŒ í™•ëŒ€ ê°œí¸ ë° ë…ë¦½ì„± ê°•í™”",
            f"{company} í™˜ê²½ì˜¤ì—¼ ë…¼ë€ì— ëŒ€í•œ ê°œì„  ê³„íš ë°œí‘œ",
        ]
        for s in samples:
            news.append({"company":company, "date": datetime.utcnow().strftime("%Y-%m-%d"), "source":"sample", "content": s})

    return pd.DataFrame(news)

    # 2) ë„¤ì´ë²„ ê²€ìƒ‰ API (ì„ íƒ)
    if not news:
        cid = st.secrets.get("NAVER_CLIENT_ID")
        csec = st.secrets.get("NAVER_CLIENT_SECRET")
        if cid and csec:
            url = "https://openapi.naver.com/v1/search/news.json"
            headers = {"X-Naver-Client-Id": cid, "X-Naver-Client-Secret": csec}
            params = {"query": query, "display": 40, "sort": "sim"}
            try:
                data = cached_json_get(url, headers=headers, params=params)
                for it in data.get("items", []):
                    title = it.get("title","").replace("<b>","").replace("</b>","")
                    desc = it.get("description","").replace("<b>","").replace("</b>","")
                    news.append({"company":company, "date":datetime.utcnow().strftime("%Y-%m-%d"), "source":"naver", "content":f"{title} {desc}"})
            except Exception:
                pass

    # 3) ìƒ˜í”Œ(ë°±ì—…)
    if not news:
        samples = [
            f"{company} íƒ„ì†Œì¤‘ë¦½ ë¡œë“œë§µ ë°œí‘œ, ì¬ìƒì—ë„ˆì§€ ì‚¬ìš© í™•ëŒ€",
            f"{company} í˜‘ë ¥ì‚¬ì™€ì˜ ìƒìƒ í”„ë¡œê·¸ë¨ ê°•í™”, ì‚¬íšŒì  ì±…ì„ í™•ëŒ€",
            f"{company} ESG ìœ„ì›íšŒ í™•ëŒ€ ê°œí¸ ë° ë…ë¦½ì„± ê°•í™”",
            f"{company} í™˜ê²½ì˜¤ì—¼ ë…¼ë€ì— ëŒ€í•œ ê°œì„  ê³„íš ë°œí‘œ",
        ]
        for s in samples:
            news.append({"company":company, "date": datetime.utcnow().strftime("%Y-%m-%d"), "source":"sample", "content": s})

    return pd.DataFrame(news)

# -----------------------------------------------------
# ESG ì ìˆ˜í™”
# -----------------------------------------------------
ANALYZER = SentimentIntensityAnalyzer()

# ê°„ë‹¨ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜(í™˜ê²½/ì‚¬íšŒ/ì§€ë°°êµ¬ì¡°)
KEYWORD_W = {
    "í™˜ê²½": ["íƒ„ì†Œ", "ì˜¨ì‹¤ê°€ìŠ¤", "ì¬ìƒì—ë„ˆì§€", "ì¹œí™˜ê²½", "ë°°ì¶œê¶Œ", "ë„·ì œë¡œ", "ìˆ˜ì†Œ", "íƒœì–‘ê´‘", "í’ë ¥"],
    "ì‚¬íšŒ": ["ì•ˆì „", "ë…¸ë™", "ìƒìƒ", "ì§€ì—­ì‚¬íšŒ", "ê¸°ë¶€", "ë³µì§€", "ìœ¤ë¦¬", "ë‹¤ì–‘ì„±"],
    "ì§€ë°°êµ¬ì¡°": ["ì´ì‚¬íšŒ", "ê°ì‚¬", "ë‚´ë¶€í†µì œ", "ì§€ë°°êµ¬ì¡°", "ì£¼ì£¼", "ê³µì‹œ", "íˆ¬ëª…ì„±"],
}
def keyword_boost(text: str)->float:
    score = 0.0
    for cat, words in KEYWORD_W.items():
        for w in words:
            if w in text:
                score += 0.1
    return score

def esg_score_one(text: str)->float:
    s = ANALYZER.polarity_scores(text)["compound"]  # -1~1
    s += keyword_boost(text)
    return float(np.clip(s, -1, 1))

# -----------------------------------------------------
# ì „ì²´ íŒŒì´í”„ë¼ì¸: ìˆ˜ì§‘â†’ì ìˆ˜í™”â†’ì§‘ê³„â†’ì£¼ê°€/ì‹œì´ ê²°í•©
# -----------------------------------------------------
@st.cache_data(ttl=60*30)
def build_results(companies, days_back: int):
    rows = []
    price_frames = []

    start_date = (datetime.today() - timedelta(days=365*5)).strftime("%Y-%m-%d")

    for comp in companies:
        info = COMPANY_MAP[comp]
        q = info["query"]
        tkr = info["ticker"]

        # ë‰´ìŠ¤ ìˆ˜ì§‘
        df_news = fetch_news(comp, q, days_back)
        # ì ìˆ˜í™”
        df_news["esg_score"] = df_news["content"].apply(esg_score_one)

        # íšŒì‚¬ë³„ ì§‘ê³„ (í‰ê· /ìµœì‹ /ë¬¸ì„œìˆ˜)
        if not df_news.empty:
            esg_avg = df_news["esg_score"].mean()
            esg_last = df_news.sort_values("date")["esg_score"].iloc[-1]
            n_docs = len(df_news)
        else:
            esg_avg, esg_last, n_docs = 0, 0, 0

        # ì£¼ê°€/ì‹œì´
        px_hist = fetch_yf_history(tkr, start_date)
        market_cap = fetch_yf_fastinfo(tkr)  # ì—†ìœ¼ë©´ None

        # ì—°ë„ë³„ë¡œ ê²°ê³¼ ë¿Œë¦¬ê¸° (ì£¼ê°€ê°€ ìˆìœ¼ë©´ ë§¤ì¹­)
        if not px_hist.empty:
            for y, grp in px_hist.groupby("year"):
                stock_price = float(grp.tail(1)["stock_price"].values[0])
                rows.append({
                    "company": comp,
                    "year": int(y),
                    "esg_avg": round(esg_avg,4),
                    "esg_last": round(esg_last,4),
                    "n_docs": int(n_docs),
                    "stock_price": stock_price,
                    "market_cap": market_cap if market_cap is not None else np.nan,
                })
        else:
            # ê°€ê²©ì´ ì „í˜€ ì—†ìœ¼ë©´ ìµœê·¼ ì—°ë„ 1ê±´ë§Œ
            rows.append({
                "company": comp,
                "year": datetime.today().year,
                "esg_avg": round(esg_avg,4),
                "esg_last": round(esg_last,4),
                "n_docs": int(n_docs),
                "stock_price": np.nan,
                "market_cap": market_cap if market_cap is not None else np.nan,
            })

    df_res = pd.DataFrame(rows)
    if not df_res.empty:
        df_res.sort_values(["company","year"], inplace=True)
    return df_res

df = build_results(companies, days)

# í•„ìš”í•˜ë©´ CSVë¡œë„ ë³´ê´€ (ì œì¶œë¬¼ ìš”êµ¬ ì‹œ)
base_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
out_path = os.path.join(base_path, "results.csv")
try:
    df.to_csv(out_path, index=False, encoding="utf-8-sig")
except Exception:
    pass

# -----------------------------------------------------
# ìƒë‹¨: Top5 / ì‚¬ì´ë“œë°”-ë³¸ë¬¸ ë™ê¸° ì„ íƒ
# -----------------------------------------------------
st.sidebar.markdown("---")
company_sidebar = st.sidebar.selectbox("ğŸ“Œ ìƒì„¸ ê¸°ì—… ì„ íƒ", companies)

# ë³¸ë¬¸ì—ë„ ë™ì¼ ì„ íƒ ë°•ìŠ¤(ë™ê¸°í™”)
company = st.selectbox(
    "ê¸°ì—… ì„ íƒ (ë³¸ë¬¸)",
    companies,
    index=companies.index(company_sidebar)
)

if company != company_sidebar:
    st.sidebar.success(f"ì‚¬ì´ë“œë°” ì„ íƒë„ â€˜{company}â€™ë¡œ ë™ê¸°í™”í•´ ì£¼ì„¸ìš”.")

# -----------------------------------------------------
# ë¯¸ë¦¬ë³´ê¸° í‘œ
# -----------------------------------------------------
with st.expander("ğŸ“‚ ê²°ê³¼ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (API ì§‘ê³„ ê²°ê³¼)"):
    st.dataframe(df.head(20))

# -----------------------------------------------------
# Company Details
# -----------------------------------------------------
st.subheader(f"ğŸ“Œ ê¸°ì—… ì •ë³´ : {company}")
company_data = df[df["company"] == company].sort_values("year")
if company_data.empty:
    st.warning("ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
else:
    latest = company_data.iloc[-1]
    colA, colB, colC = st.columns(3)
    with colA:
        st.metric("ESG í‰ê· ", f"{latest['esg_avg']}")
    with colB:
        st.metric("ESG ìµœì‹ ", f"{latest['esg_last']}")
    with colC:
        st.metric("ë¬¸ì„œ ìˆ˜", f"{int(latest['n_docs'])}")

    col1, col2 = st.columns(2)
    with col1:
        st.line_chart(company_data.set_index("year")["esg_last"], height=300)
        st.caption("ESG ì ìˆ˜ ì¶”ì´")
    with col2:
        st.line_chart(company_data.set_index("year")["stock_price"], height=300)
        st.caption("ì£¼ê°€ ì¶”ì´")

    # ì‹œì¥ê°€ì¹˜(ê°€ëŠ¥í•œ ê²½ìš°)
    if "market_cap" in company_data.columns and company_data["market_cap"].notna().any():
        mc = company_data["market_cap"].dropna().iloc[-1]
        st.caption(f"ì°¸ê³ : í˜„ì¬ ì‹œê°€ì´ì•¡(ì›í™” í™˜ì‚° ì „ ì›ë‹¨ìœ„, ë°ì´í„° ì œê³µ ë²”ìœ„ì— ë”°ë¼ ê³µë€ ê°€ëŠ¥) â‰ˆ {mc:,}")

# -----------------------------------------------------
# ë¹„êµ(Radar)
# -----------------------------------------------------
st.subheader("ğŸ“Š ê¸°ì—… ë¹„êµ (Radar)")
if len(companies) >= 2:
    cmpA = st.selectbox("ë¹„êµ ê¸°ì—… A", companies, index=0, key="cmpA")
    cmpB = st.selectbox("ë¹„êµ ê¸°ì—… B", companies, index=1, key="cmpB")

    cats = ["ESG í‰ê· ", "ESG ìµœì‹ ", "ë¬¸ì„œ ìˆ˜"]
    def stats(c):
        sub = df[df["company"] == c]
        return [
            sub["esg_avg"].mean(skipna=True),
            sub["esg_last"].mean(skipna=True),
            sub["n_docs"].mean(skipna=True),
        ]
    valsA, valsB = stats(cmpA), stats(cmpB)
    df_radar = pd.DataFrame({"Category": cats, cmpA: valsA, cmpB: valsB})

    fig = px.line_polar(df_radar, r=cmpA, theta="Category", line_close=True)
    fig.update_traces(name=cmpA, showlegend=True)
    fig.add_scatterpolar(r=df_radar[cmpB], theta=df_radar["Category"], name=cmpB)
    st.plotly_chart(fig, use_container_width=True)
else:
    st.info("ë¹„êµí•  ê¸°ì—…ì„ 2ê°œ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.")

# -----------------------------------------------------
# ì¶”ì²œ ì¹´ë“œ (ìƒìœ„ 3ê°œ)
# -----------------------------------------------------
st.subheader("âœ… ì¶”ì²œ ê¸°ì—…")
top3 = df.groupby("company")["esg_avg"].mean().nlargest(3).reset_index()
c1,c2,c3 = st.columns(3)
for i, c in enumerate([c1,c2,c3]):
    if i < len(top3):
        row = top3.iloc[i]
        with c:
            st.metric(row["company"], round(row["esg_avg"],2), "ESG í‰ê· ")
